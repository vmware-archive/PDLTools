/* ----------------------------------------------------------------------- *//**

@file grid_search.sql_in

@brief A set of grid search functions for various algorithms. 

@author Written by Srivatsan Ramanujam, April Song, Joseph Greubel
@date 07 Apr 2016

 *//* ----------------------------------------------------------------------- */

 /**
@addtogroup grp_kmeans

@brief A function for grid search over k-Means.

<div class="toc"><b>Contents</b>
<ul>
<li class="level1"><a href="#kmeans_syntax">Syntax</a>
<li class="level1"><a href="#kmeans_usage">Usage</a>
<li class="level1"><a href="#kmeans_example">Example</a>
</ul>
</div>

@about
A function that run's MADlib's k-Means function with varying values for k and saves the model outputs into one table. See the <A HREF="http://madlib.incubator.apache.org/docs/v1.8/group__grp__kmeans.html">MADlib's documentation</A> for more details. 

@anchor kmeans_syntax
@par Syntax
The k-means algorithm can be invoked in two ways, depending on the source of the initial set of centroids:<ul>

<li>Use the kmeans random centroid seeding method.<br>
<pre class="syntax">
FUNCTION gs_kmeans_random( id_column text,
                      mdl_output_tbl text,
                      num_clusters_arr int[],
                      rel_source text,
                      expr_point text,
                      fn_dist text,
                      agg_centroid text,
                      max_num_iterations integer,
                      min_frac_reassigned double precision
                    )
returns text;
</pre>
</li>

<li>Use the kmeans++ centroid seeding method.<br>
<pre class="syntax">
FUNCTION gs_kmeanspp( id_column text,
                      mdl_output_tbl text,
                      num_clusters_arr int[],
                      rel_source text,
                      expr_point text,
                      fn_dist text,
                      agg_centroid text,
                      max_num_iterations integer,
                      min_frac_reassigned double precision,
                      seeding_sample_ratio double precision
                    )
returns text;
</pre>
</li>


</ul>

@param id_column  ID column of the input table. 
@param mdl_output_tbl Name of table to store model outputs. 
@param num_clusters_arr Array of k values for which to run clustering. 
@param rel_source The name of the table containing the input data points.<br>Data points and predefined centroids (if used) are expected to be stored row-wise, in a column of type <tt>"SVEC"</tt> (or any type convertible to <tt>"SVEC"</tt>, like <tt>FLOAT[]</tt> or <tt>INTEGER[]</tt>). Data points with non-finite values (NULL, NaN, infinity) in any component are skipped during analysis.
@param expr_point The name of the column with point coordinates.
@param fn_dist(optional)    The name of the function to use to calculate the distance from a data point to a centroid. Default: 'squared_dist_norm2'. <br><br>The following distance functions can be used (computation of barycenter/mean in parentheses):
<ul>
<li><b>dist_norm1</b>:  1-norm/Manhattan (element-wise median
[Note that MADlib does not provide a median aggregate function for support and
performance reasons.])</li>
<li><b>dist_norm2</b>: 2-norm/Euclidean (element-wise mean)</li>
<li><b>squared_dist_norm2</b>: squared Euclidean distance (element-wise mean)</li>
<li><b>dist_angle</b>: angle (element-wise mean of normalized points)</li>
<li><b>dist_tanimoto</b>: tanimoto (element-wise mean of normalized points)</li>
<li><b>user defined function</b> with signature <tt>DOUBLE PRECISION[] x, DOUBLE PRECISION[] y -> DOUBLE PRECISION</tt></li></ul><br>See the <a href="http://madlib.incubator.apache.org/docs/v1.8/group__grp__kmeans.html">MADlib's documentation</a> for more details. 
@param agg_centroid (optional)  The name of the aggregate function used to determine centroids. Default: 'avg'.<br><br>The following aggregate functions can be used:<ul>
 <li><b>avg</b>: average (Default)</li>
 <li><b>normalized_avg</b>: normalized average</li></ul>
@param max_num_iterations (optional)  The maximum number of iterations to perform. Default: 20.
@param min_frac_reassigned (optional)  The minimum fraction of centroids reassigned to continue iterating. When fewer than this fraction of centroids are reassigned in an iteration, the calculation completes. Default: 0.001.
@param seeding_sample_ratio (optional)  The proportion of subsample of original dataset to use for kmeans++ centroid seeding method. Kmeans++ scans through the data sequentially 'k' times and can be too slow for big datasets. When 'seeding_sample_ratio' is greater than 0 (thresholded to be maximum value of 1.0), the seeding is run on an uniform random subsample of the data. Note: the final K-means algorithm is run on the complete dataset. This parameter only builds a subsample for the seeding and is only available for kmeans++. Default: 1.0.  


@returns Name of table in which MADlib's k-Means model outputs for each k are saved.

@anchor kmeans_usage
@usage
Given an array of k values, the function runs MADlib's k-Means clustering with random or kmeans++ centroid seeding. Usage is identical to MADlib's function with the additional parameters of an id column and array of k values. 

@anchor kmeans_example
@examp
Create sample data.
@verbatim
-- create input table
CREATE TABLE km_sample(pid int, points double precision[]);
COPY km_sample (pid, points) FROM stdin DELIMITER '|';
1 | {14.23, 1.71, 2.43, 15.6, 127, 2.8, 3.0600, 0.2800, 2.29, 5.64, 1.04, 3.92, 1065}
2 | {13.2, 1.78, 2.14, 11.2, 1, 2.65, 2.76, 0.26, 1.28, 4.38, 1.05, 3.49, 1050}
3 | {13.16, 2.36,  2.67, 18.6, 101, 2.8,  3.24, 0.3, 2.81, 5.6799, 1.03, 3.17, 1185}
4 | {14.37, 1.95, 2.5, 16.8, 113, 3.85, 3.49, 0.24, 2.18, 7.8, 0.86, 3.45, 1480}
5 | {13.24, 2.59, 2.87, 21, 118, 2.8, 2.69, 0.39, 1.82, 4.32, 1.04, 2.93, 735}
6 | {14.2, 1.76, 2.45, 15.2, 112, 3.27, 3.39, 0.34, 1.97, 6.75, 1.05, 2.85, 1450}
7 | {14.39, 1.87, 2.45, 14.6, 96, 2.5, 2.52, 0.3, 1.98, 5.25, 1.02, 3.58, 1290}
8 | {14.06, 2.15, 2.61, 17.6, 121, 2.6, 2.51, 0.31, 1.25, 5.05, 1.06, 3.58, 1295}
9 | {14.83, 1.64, 2.17, 14, 97, 2.8, 2.98, 0.29, 1.98, 5.2, 1.08, 2.85, 1045}
10 | {13.86, 1.35, 2.27, 16, 98, 2.98, 3.15, 0.22, 1.8500, 7.2199, 1.01, 3.55, 1045}
\.
@endverbatim

Run kmeans++ using without specifying seeding_sample_ratio
@verbatim
-- run kmeans++
select
    gs_kmeanspp(
        'pid'
        ,'kmeans_output'
        ,ARRAY[2,3,4]
        ,'km_sample'
        ,'points'
        ,'madlib.squared_dist_norm2'
        ,'madlib.avg'
        ,20
        ,0.001
        );

                     gs_kmeanspp                     
-----------------------------------------------------
 Model parameters written to asong.kmeans_output table
(1 row)

-- view model results
select * from kmeans_output order by simple_silhouette;
-[ RECORD 1 ]-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 2
centroids         | {{14.036,2.018,2.536,16.56,108.6,3.004,3.03,0.298,2.038,6.10598,1.004,3.326,1340},{13.872,1.814,2.376,15.56,88.2,2.806,2.928,0.288,1.844,5.35198,1.044,3.702,988}}
objective_fn      | 151188.184071616
frac_reassigned   | 0
num_iterations    | 2
simple_silhouette | 0.868171470276621
-[ RECORD 2 ]-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 3
centroids         | {{14.285,1.855,2.475,16,112.5,3.56,3.44,0.29,2.075,7.275,0.955,3.15,1465},{13.872,1.814,2.376,15.56,88.2,2.806,2.928,0.288,1.844,5.35198,1.044,3.702,988},{13.87,2.12666666666667,2.57666666666667,16.9333333333333,106,2.63333333333333,2.75666666666667,0.303333333333333,2.01333333333333,5.32663333333333,1.03666666666667,3.44333333333333,1256.66666666667}}
objective_fn      | 99046.5355890814
frac_reassigned   | 0
num_iterations    | 2
simple_silhouette | 0.914699786660885
-[ RECORD 3 ]-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 4
centroids         | {{14.04,1.8225,2.435,16.65,110,2.845,2.97,0.295,1.985,5.594975,1.0425,3.755,972.5},{14.285,1.855,2.475,16,112.5,3.56,3.44,0.29,2.075,7.275,0.955,3.15,1465},{13.87,2.12666666666667,2.57666666666667,16.9333333333333,106,2.63333333333333,2.75666666666667,0.303333333333333,2.01333333333333,5.32663333333333,1.03666666666667,3.44333333333333,1256.66666666667},{13.2,1.78,2.14,11.2,1,2.65,2.76,0.26,1.28,4.38,1.05,3.49,1050}}
objective_fn      | 84710.6365876808
frac_reassigned   | 0
num_iterations    | 2
simple_silhouette | 0.941390939063272
@endverbatim

Run kmeans++ using without specifying max_num_iterations, min_frac_reassigned, seeding_sample_ratio
@verbatim
-- run kmeans++ 
select
    gs_kmeanspp(
        'pid'
        ,'kmeans_output2'
        ,ARRAY[2,3,4]
        ,'km_sample'
        ,'points'
        ,'madlib.squared_dist_norm2'
        ,'madlib.avg'
        );

                     gs_kmeanspp                     
-----------------------------------------------------
 Model parameters written to kmeans_output2 table
(1 row)

-- view model results
select * from kmeans_output2 order by simple_silhouette;
-[ RECORD 1 ]-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 3
centroids         | {{14.255,1.9325,2.5025,16.05,110.5,3.055,2.9775,0.2975,1.845,6.2125,0.9975,3.365,1378.75},{13.24,2.59,2.87,21,118,2.8,2.69,0.39,1.82,4.32,1.04,2.93,735},{13.856,1.768,2.336,15.08,84.8,2.806,3.038,0.27,2.042,5.62396,1.042,3.75,1078}}
objective_fn      | 54572.469119612
frac_reassigned   | 0
num_iterations    | 4
simple_silhouette | 0.797509804656949
-[ RECORD 2 ]-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 2
centroids         | {{14.255,1.9325,2.5025,16.05,110.5,3.055,2.9775,0.2975,1.845,6.2125,0.9975,3.365,1378.75},{13.7533333333333,1.905,2.425,16.0666666666667,90.3333333333333,2.805,2.98,0.29,2.005,5.40663333333333,1.04166666666667,3.61333333333333,1020.83333333333}}
objective_fn      | 153564.289316013
frac_reassigned   | 0
num_iterations    | 2
simple_silhouette | 0.872084325515476
-[ RECORD 3 ]-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 4
centroids         | {{14.285,1.855,2.475,16,112.5,3.56,3.44,0.29,2.075,7.275,0.955,3.15,1465},{13.24,2.59,2.87,21,118,2.8,2.69,0.39,1.82,4.32,1.04,2.93,735},{14.03,1.62,2.2525,14.2,80.75,2.8075,2.9875,0.2625,1.85,5.609975,1.045,3.895,1051.25},{13.87,2.12666666666667,2.57666666666667,16.9333333333333,106,2.63333333333333,2.75666666666667,0.303333333333333,2.01333333333333,5.32663333333333,1.03666666666667,3.44333333333333,1256.66666666667}}
objective_fn      | 17884.5257406808
frac_reassigned   | 0
num_iterations    | 2
simple_silhouette | 0.941390939063272

@endverbatim
Run kmeans with random centroid seeding
@verbatim
-- run kmeans with random centroid seeding
select 
    gs_kmeans_random(
        'pid'
        ,'kmeans_output3'
        ,ARRAY[2,3,4]
        ,'km_sample'
        ,'points'
        ,'madlib.squared_dist_norm2'
        ,'madlib.avg'
        ,30
        ,0.001
    );

                     gs_kmeans_random                     
-----------------------------------------------------
 Model parameters written to kmeans_output3 table
(1 row)

-- view model results
select * from kmeans_output3 order by simple_silhouette;
-[ RECORD 1 ]-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 2
centroids         | {{13.872,1.814,2.376,15.56,88.2,2.806,2.928,0.288,1.844,5.35198,1.044,3.702,988},{14.036,2.018,2.536,16.56,108.6,3.004,3.03,0.298,2.038,6.10598,1.004,3.326,1340}}
objective_fn      | 151188.184071616
frac_reassigned   | 0
num_iterations    | 2
simple_silhouette | 0.861734476983939
-[ RECORD 2 ]-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 3
centroids         | {{14.04,1.8225,2.435,16.65,110,2.845,2.97,0.295,1.985,5.594975,1.0425,3.755,972.5},{13.2,1.78,2.14,11.2,1,2.65,2.76,0.26,1.28,4.38,1.05,3.49,1050},{14.036,2.018,2.536,16.56,108.6,3.004,3.03,0.298,2.038,6.10598,1.004,3.326,1340}}
objective_fn      | 136852.285070215
frac_reassigned   | 0
num_iterations    | 2
simple_silhouette | 0.914699786660885
-[ RECORD 3 ]-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 4
centroids         | {{13.87,2.12666666666667,2.57666666666667,16.9333333333333,106,2.63333333333333,2.75666666666667,0.303333333333333,2.01333333333333,5.32663333333333,1.03666666666667,3.44333333333333,1256.66666666667},{13.872,1.814,2.376,15.56,88.2,2.806,2.928,0.288,1.844,5.35198,1.044,3.702,988},{14.37,1.95,2.5,16.8,113,3.85,3.49,0.24,2.18,7.8,0.86,3.45,1480},{14.2,1.76,2.45,15.2,112,3.27,3.39,0.34,1.97,6.75,1.05,2.85,1450}}
objective_fn      | 98593.7722890813
frac_reassigned   | 0
num_iterations    | 3
simple_silhouette | 0.941390939063272
@endverbatim

Run kmeans with random centroid seeding using without specifying fn_dist, agg_centroid,max_num_iterations, min_frac_reassigned
@verbatim
-- run kmeans with random centroid seeding
select
    gs_kmeans_random(
        'pid'
        ,'kmeans_output4'
        ,ARRAY[2,3,4]
        ,'km_sample'
        ,'points'
    );

                     gs_kmeans_random                     
-----------------------------------------------------
 Model parameters written to kmeans_output4 table
(1 row)

-- view model results
select * from kmeans_output4 order by simple_silhouette;
-[ RECORD 1 ]-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 3
centroids         | {{13.87,2.12666666666667,2.57666666666667,16.9333333333333,106,2.63333333333333,2.75666666666667,0.303333333333333,2.01333333333333,5.32663333333333,1.03666666666667,3.44333333333333,1256.66666666667},{13.872,1.814,2.376,15.56,88.2,2.806,2.928,0.288,1.844,5.35198,1.044,3.702,988},{14.285,1.855,2.475,16,112.5,3.56,3.44,0.29,2.075,7.275,0.955,3.15,1465}}
objective_fn      | 99046.5355890813
frac_reassigned   | 0
num_iterations    | 4
simple_silhouette | 0.797509804656949
-[ RECORD 2 ]-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 2
centroids         | {{14.255,1.9325,2.5025,16.05,110.5,3.055,2.9775,0.2975,1.845,6.2125,0.9975,3.365,1378.75},{13.7533333333333,1.905,2.425,16.0666666666667,90.3333333333333,2.805,2.98,0.29,2.005,5.40663333333333,1.04166666666667,3.61333333333333,1020.83333333333}}
objective_fn      | 153564.289316013
frac_reassigned   | 0
num_iterations    | 2
simple_silhouette | 0.868171470276621
-[ RECORD 3 ]-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
num_clusters      | 4
centroids         | {{13.16,2.36,2.67,18.6,101,2.8,3.24,0.3,2.81,5.6799,1.03,3.17,1185},{14.285,1.855,2.475,16,112.5,3.56,3.44,0.29,2.075,7.275,0.955,3.15,1465},{14.225,2.01,2.53,16.1,108.5,2.55,2.515,0.305,1.615,5.15,1.04,3.58,1292.5},{13.872,1.814,2.376,15.56,88.2,2.806,2.928,0.288,1.844,5.35198,1.044,3.702,988}}
objective_fn      | 91298.207926408
frac_reassigned   | 0
num_iterations    | 2
simple_silhouette | 0.877815152206439
@endverbatim

 */


/**
@addtogroup grp_elastic_net

@brief A function for grid search over Elastic Net wth k-fold cross validation.

<div class="toc"><b>Contents</b>
<ul>
<li class="level1"><a href="#elasticnet_syntax">Syntax</a>
<li class="level1"><a href="#elasticnet_usage">Usage</a>
<li class="level1"><a href="#elasticenet_example">Example</a>
</ul>
</div>

@about
Elastic Nets combine the the benefits of L1 and L2 regularizations with regression models. L1 regularization results in very sparse features, while L2 regularization results in features whose coefficients are closer to zero. By adjusting the alpha and lambda parameters, we can achieve the benefits of both L1 and L2 regularization. Refer to <A HREF="http://madlib.incubator.apache.org/docs/latest/group__grp__elasticnet.html">MADlib Elastic Net Regression</A> for more information.

@anchor elasticnet_syntax
@par Syntax
<pre class="syntax">
FUNCTION gs_elasticnet_cv(
    tbl_source text, 
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean, -- OPTIONAL, default: TRUE
    optimizer text, -- OPTIONAL, default: 'fista'
    optimizer_params text, -- OPTIONAL, defaut: NULL
    excluded text, -- OPTIONAL, default: NULL
    max_iter integer, -- OPTIONAL, default: 1000
    tolerance float8 -- OPTIONAL, default is 1e-6
returns text;
</pre>


@param tbl_source The name of the table containing the training data.
@param tbl_result Name of the generated table containing the output model.
@param col_dep_var Name of label column in input table. 
@param col_ind_var Name of features column in input table. Use '*' to specify all columns of tbl_source except those listed in the excluded string.
@param regress_family The regression type, either 'gaussian' ('linear') or 'binomial' ('logistic').
@param alphas List of elastic net control parameters, values in [0, 1], 1 for L-1 regularization, 0 for L-2.
@param lambdas List of regularization parameter, positive values.  
@param id_column The name of id column in input table.
@param mdl_table intermediate table to store elastic net models 
@param k_folds The number of folds for cross-validation.
@param standardize (optional)  Whether to normalize the data. Setting this to TRUE usually yields better results and faster convergence. Default: TRUE.
@param optimizer (optional)  The name of optimizer, either 'fista' or 'igd'. Default: 'fista'.
@param optimizer_params (optional)  Optimizer parameters, delimited with commas, defaut: NULL.
@param excluded (optional)  If the col_ind_var input is '*' then excluded can be provided as a comma-delimited list of column names that are to be excluded from the features. Default: NULL 
@param max_iter (optional)  The maximum number of iterations that are allowed. Default: 1000.
@param tolerance (optional)  Criteria to end iterations. Default is 1e-6.


@returns Name of table in which grid search results are saved.

@anchor elasticnet_usage
@usage
Given an array of alphas and lambdas, the function runs MADlib's Elastic Net Regularization with k-fold cross-validation. The resulting table contains the AUC values for each model iteration. Refer to <A HREF="http://madlib.incubator.apache.org/docs/latest/group__grp__elasticnet.html">MADlib Elastic Net Regression</A> for more information.

@anchor elasticnet_example
@examp
Create sample data.
@verbatim
DROP TABLE IF EXISTS houses_sample;
CREATE TABLE houses_sample ( id INT,
                      tax INT,
                      bedroom INT,
                      bath FLOAT,
                      price INT,
                      size INT,
                      lot INT
                    );
COPY houses_sample FROM STDIN WITH DELIMITER '|';
  1 |  590 |       2 |    1 |  50000 |  770 | 22100
  2 | 1050 |       3 |    2 |  85000 | 1410 | 12000
  3 |   20 |       3 |    1 |  22500 | 1060 |  3500
  4 |  870 |       2 |    2 |  90000 | 1300 | 17500
  5 | 1320 |       3 |    2 | 133000 | 1500 | 30000
  6 | 1350 |       2 |    1 |  90500 |  820 | 25700
  7 | 2790 |       3 |  2.5 | 260000 | 2130 | 25000
  8 |  680 |       2 |    1 | 142500 | 1170 | 22000
  9 | 1840 |       3 |    2 | 160000 | 1500 | 19000
 10 | 3680 |       4 |    2 | 240000 | 2790 | 20000
 11 | 1660 |       3 |    1 |  87000 | 1030 | 17500
 12 | 1620 |       3 |    2 | 118600 | 1250 | 20000
 13 | 3100 |       3 |    2 | 140000 | 1760 | 38000
 14 | 2070 |       2 |    3 | 148000 | 1550 | 14000
 15 |  650 |       3 |  1.5 |  65000 | 1450 | 12000
\.
@endverbatim

Run elastic net with some different alphas and lambdas. 
@verbatim
select gs_elasticnet_cv(
    'houses',
    'houses_en',
    'price',
    'array[tax, bath, size]',
    'gaussian',
    ARRAY[0.05, 0.20], -- alphas
    ARRAY[0.05, 0.20], -- lambdas
    'id',
    'elastic_net_mdls',
    2,
    TRUE,
    'fista',
    NULL,
    NULL,
    10000,
    1e-6
);
             gs_elasticnet_cv             
------------------------------------------
 Grid search results written to houses_en
(1 row)
@endverbatim

View results.
@verbatim
select * from houses_en;
 alpha | lamda | fold | auc 
-------+-------+------+-----
  0.05 |   0.2 |    0 | 0.5
  0.05 |   0.2 |    1 | 0.5
  0.05 |  0.05 |    0 | 0.5
  0.05 |  0.05 |    1 | 0.5
   0.2 |  0.05 |    0 | 0.5
   0.2 |  0.05 |    1 | 0.5
   0.2 |   0.2 |    0 | 0.5
   0.2 |   0.2 |    1 | 0.5
(8 rows)
@endverbatim

 */


/**
@addtogroup grp_lda_grid_search

@brief A function for LDA grid search.

<div class="toc"><b>Contents</b>
<ul>
<li class="level1"><a href="#lda_grid_syntax">Syntax</a>
<li class="level1"><a href="#lda_grid_usage">Usage</a>
<li class="level1"><a href="#lda_grid_example">Example</a>
</ul>
</div>

@about
Latent Dirichlet Allocation (LDA) is an interesting generative probabilistic model for natural texts. The LDA model posits that each document is associated with a mixture of various topics (e.g. a document is related to Topic 1 with probability 0.7, and Topic 2 with probability 0.3), and that each word in the document is attributable to one of the document's topics. Refer to <A HREF="https://madlib.incubator.apache.org/docs/latest/group__grp__lda.html"> MADLib LDA </A> for more information. 


@anchor lda_grid_syntax
@par Syntax
<pre class="syntax">
FUNCTION lda_gridsearch(
    alphas float8[],
    betas float8[],
    num_topic_arr int[],
    input_table text,
    mdl_table text,
    output_table text,
)
returns text;
</pre>


@param alphas array for the per-doc topic multinomial
@param betas array for the per-topic word multinomial 
@param topics number of topics array
@param input LDA Input table 
@param model LDA model table
@param output LDA Output table


@returns Name of table in which grid search results are saved.

@anchor lda_grid_usage
@usage
Given an array of alphas and betas, the function runs the LDA grid search on the input table and provides the model and outout of the grid search.

@anchor lda_grid_example
@examp
Create sample data.
@verbatim
DROP TABLE IF EXISTS documents;
CREATE TABLE houses_sample ( docId INT,
                      contents TEXT,
                    );
INSERT INTO documents VALUES
(0, 'Statistical topic models are a class of Bayesian latent variable models, originally developed for analyzing the semantic content of large document corpora.'),
(1, 'By the late 1960s, the balance between pitching and hitting had swung in favor of the pitchers. In 1968 Carl Yastrzemski won the American League batting title with an average of just .301, the lowest in history.'),
(2, 'Machine learning is closely related to and often overlaps with computational statistics; a discipline that also specializes in prediction-making. It has strong ties to mathematical optimization, which deliver methods, theory and application domains to the field.'),
(3, 'California''s diverse geography ranges from the Sierra Nevada in the east to the Pacific Coast in the west, from the Redwoodâ€“Douglas fir forests of the northwest, to the Mojave Desert areas in the southeast. The center of the state is dominated by the Central Valley, a major agricultural area. ')
@endverbatim

Convert String to a list of words

@verbatim
ALTER TABLE documents ADD COLUMN words TEXT[];
UPDATE documents SET words = regexp_split_to_array(lower(contents), E'[\\s+\\.\\,]');
@endverbatim


Create Term Frequency Table 
@verbatim
DROP TABLE IF EXISTS training;
SELECT madlib.term_frequency('documents', 'docid', 'words', 'training', TRUE);

@endverbatim

Run grid search with some different alphas and lambdas. 
@verbatim
  

 select
        lda_gridsearch(
            ARRAY[0.05, 0.10, 0.20], --alphas (smaller the value, sparser the distribution
            ARRAY[0.05, 0.10, 0.20], --betas (smaller the value, sparser the distribution
            ARRAY[60, 40, 20], -- num_topics array,
            'training', -- LDA input table
            'twenty_news_groups_lda_mdl', -- LDA model table
            'twenty_news_groups_lda_gridsearch_results' --output table
        ); 


                                 lda_gridsearch                                  
---------------------------------------------------------------------------------
 Grid search results written to twenty_news_groups_lda_gridsearch_results


@endverbatim

View results.
@verbatim
select  topic_num,   alpha,  beta, lda_get_perplexity as perplexity  from   kaggle.twenty_news_groups_lda_gridsearch_results order by lda_get_perp;
 topic_num | alpha | beta |  perplexity   
-----------+-------+------+---------------
        20 |  0.05 | 0.05 |  42.974155139
        20 |   0.1 | 0.05 | 47.5286308135
        40 |  0.05 | 0.05 | 47.8441436384
        60 |  0.05 | 0.05 | 49.0871729058
        40 |  0.05 |  0.1 | 49.3048227706
        20 |  0.05 |  0.1 | 49.5827040155
        20 |   0.2 | 0.05 | 51.0495079723
        20 |   0.2 |  0.1 | 52.0790791152
        40 |   0.1 | 0.05 | 52.4788076556
        20 |   0.1 |  0.1 | 52.6573694225
        60 |   0.1 | 0.05 | 53.8439078734
        60 |  0.05 |  0.1 | 54.3546251907
        40 |  0.05 |  0.2 | 56.6177604318
        20 |  0.05 |  0.2 | 56.7466389605
        40 |   0.2 | 0.05 | 57.1590080682
        60 |  0.05 |  0.2 |  58.047604261
        20 |   0.1 |  0.2 | 60.3628285358
        60 |   0.1 |  0.1 | 60.7553194771
        60 |   0.2 | 0.05 | 61.0020140338
        40 |   0.1 |  0.1 | 61.6111169233
        60 |   0.2 |  0.1 | 62.3893799651
        40 |   0.1 |  0.2 | 62.9618429362
        40 |   0.2 |  0.1 | 63.8145476584
        20 |   0.2 |  0.2 | 65.1425615058
        40 |   0.2 |  0.2 | 66.5310001286
        60 |   0.1 |  0.2 | 66.5315782492
        60 |   0.2 |  0.2 | 71.8479999652




@endverbatim

 */
 ------------------------------------------------------------------------
 -- base kmeans function
drop function if exists PDLTOOLS_SCHEMA.grid_search_kmeans_all(
    text, 
    text, 
    int[],
    text, 
    text, 
    text, 
    text,
    text, 
    integer,
    double precision,
    double precision
) cascade;
create or replace function PDLTOOLS_SCHEMA.grid_search_kmeans_all(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],
    kmeans_func text,

    rel_source text,
    expr_point text,
    fn_dist text,
    agg_centroid text,
    max_num_iterations integer,
    min_frac_reassigned double precision,
    seeding_sample_ratio double precision
)
returns void
as
$$
    import plpy
    
    #1) Prepare a table to hold model results
    try:
        sql = '''
        --Prepare results table
        create table {mdl_output_tbl} 
        (
            num_clusters int,
            centroids double precision[],
            objective_fn double precision,
            frac_reassigned double precision,
            num_iterations int,
            simple_silhouette double precision
        ) distributed randomly;
        '''.format(mdl_output_tbl = mdl_output_tbl)
        results = plpy.execute(sql)
    except:
        plpy.error("The output table already exists")

    #3) Run MADlib K-Means with supplied arguments for each value in the num_clusters_arr array


    for num_clusters in num_clusters_arr:
        sql = '''
            insert into {{mdl_output_tbl}}
            with mdl
            as
            (
                select 
                    {{num_clusters}} as num_clusters,
                       *
                from 
                    {kmeans_func}
            )
            select 
                mdl.*,
                scoef.simple_silhouette
            from
            (
                select 
                    num_clusters,
                    --Refer: http://en.wikipedia.org/wiki/Silhouette_(clustering)
                    avg(
                        CASE  WHEN distances[2] = 0 THEN 0
                          ELSE (distances[2] - distances[1]) / distances[2]
                        END
                    ) as simple_silhouette
                from
                (
                    select 
                        ds.{{id_column}}, 
                        mdl.num_clusters,
                        ( 
                            madlib.closest_columns(
                                 mdl.centroids, 
                                 ds.{{expr_point}}, 
                                 2,
                                 '{{fn_dist}}'
                            )
                        ).distances
                    from 
                        {{rel_source}} ds, mdl
                )q
                group by 
                    num_clusters
            ) scoef, mdl
            where scoef.num_clusters = mdl.num_clusters
        '''.format(
            kmeans_func = kmeans_func)

        sql = sql.format(
            rel_source = rel_source,
            expr_point = expr_point,
            num_clusters = num_clusters,
            fn_dist = fn_dist,
            agg_centroid = agg_centroid,
            mdl_output_tbl = mdl_output_tbl,
            id_column = id_column,
            max_num_iterations = max_num_iterations,
            min_frac_reassigned = min_frac_reassigned,
            seeding_sample_ratio = seeding_sample_ratio
            )

        plpy.execute(sql)
    
$$ language plpythonu;


-- 1) UDF to iterate over K
--PL/Python Driver Function to run K-Means while varying the number of clusters
drop function if exists PDLTOOLS_SCHEMA.gs_kmeanspp(
    text, 
    text, 
    int[],
    text, 
    text, 
    text, 
    text,
    integer,
    double precision,
    double precision
) cascade;
create or replace function PDLTOOLS_SCHEMA.gs_kmeanspp(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],

    rel_source text,
    expr_point text,
    fn_dist text, -- optional, default: 'squared_dist_norm2'
    agg_centroid text, -- optional, default: 'avg'
    max_num_iterations integer, -- optional, default: 20
    min_frac_reassigned double precision, -- optional, default: 0.001
    seeding_sample_ratio double precision -- optional, default: 1.0
)
returns text
as
$$
    import plpy

    #1) Create kmeanspp function call
    kmeanspp_func = '''
        madlib.kmeanspp(
             ''{rel_source}'', 
             ''{expr_point}'', 
             {num_clusters}, 
             ''{fn_dist}'', 
             ''{agg_centroid}'', 
             {max_num_iterations}, 
             {min_frac_reassigned},
             {seeding_sample_ratio}
         )
    '''
    
    #2) Prepare a table to hold model results
    sql = '''
    select 
        PDLTOOLS_SCHEMA.grid_search_kmeans_all(
            '{id_column}',
            '{mdl_output_tbl}',
            array{num_clusters_arr},
            '{kmeans_func}',
            '{rel_source}',
            '{expr_point}',
            '{fn_dist}',
            '{agg_centroid}',
            {max_num_iterations},
            {min_frac_reassigned},
            {seeding_sample_ratio}
        );
    '''.format(
            id_column=id_column,
            mdl_output_tbl=mdl_output_tbl,
            num_clusters_arr=num_clusters_arr,
            kmeans_func=kmeanspp_func,
            rel_source=rel_source,
            expr_point=expr_point,
            fn_dist=fn_dist,
            agg_centroid=agg_centroid,
            max_num_iterations=max_num_iterations,
            min_frac_reassigned=min_frac_reassigned,
            seeding_sample_ratio=seeding_sample_ratio
        )

    plpy.execute(sql)
    return 'Model parameters written to {mdl_output_tbl} table'.format(mdl_output_tbl = mdl_output_tbl) 
$$ language plpythonu;

-- everything but seeding_sample_ratio given
CREATE OR REPLACE FUNCTION PDLTOOLS_SCHEMA.gs_kmeanspp(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],
    rel_source text,
    expr_point text,
    fn_dist text /*+ DEFAULT 'squared_dist_norm2' */,
    agg_centroid text /*+ DEFAULT 'avg' */,
    max_num_iterations integer /*+ DEFAULT 20 */,
    min_frac_reassigned double precision /*+ DEFAULT 0.001 */
) returns text AS 
$$
    declare 
        ret text;
    begin
        select PDLTOOLS_SCHEMA.gs_kmeanspp(
                id_column,
                mdl_output_tbl,
                num_clusters_arr,
                rel_source,
                expr_point,
                fn_dist,
                agg_centroid,
                max_num_iterations,
                min_frac_reassigned,
                1.0::double precision
            ) into ret;
        return ret;
    end;

$$ language plpgsql;

CREATE OR REPLACE FUNCTION PDLTOOLS_SCHEMA.gs_kmeanspp(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],
    rel_source text,
    expr_point text,
    fn_dist text /*+ DEFAULT 'squared_dist_norm2' */,
    agg_centroid text /*+ DEFAULT 'avg' */,
    max_num_iterations integer /*+ DEFAULT 20 */
) returns text AS 
$$
    declare 
        ret text;
    begin
        select PDLTOOLS_SCHEMA.gs_kmeanspp(
                id_column,
                mdl_output_tbl,
                num_clusters_arr,
                rel_source,
                expr_point,
                fn_dist,
                agg_centroid,
                max_num_iterations,
                0.001::double precision,
                1.0::double precision
            ) into ret;
        return ret;
    end;

$$ language plpgsql;

CREATE OR REPLACE FUNCTION PDLTOOLS_SCHEMA.gs_kmeanspp(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],
    rel_source text,
    expr_point text,
    fn_dist text /*+ DEFAULT 'squared_dist_norm2' */,
    agg_centroid text /*+ DEFAULT 'avg' */
) returns text AS 
$$
    declare 
        ret text;
    begin
        select PDLTOOLS_SCHEMA.gs_kmeanspp(
                id_column,
                mdl_output_tbl,
                num_clusters_arr,
                rel_source,
                expr_point,
                fn_dist,
                agg_centroid,
                20::integer,
                0.001::double precision,
                1.0::double precision
            ) into ret;
        return ret;
    end;

$$ language plpgsql;

CREATE OR REPLACE FUNCTION PDLTOOLS_SCHEMA.gs_kmeanspp(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],
    rel_source text,
    expr_point text,
    fn_dist text /*+ DEFAULT 'squared_dist_norm2' */
) returns text AS 
$$
    declare 
        ret text;
    begin
        select PDLTOOLS_SCHEMA.gs_kmeanspp(
                id_column,
                mdl_output_tbl,
                num_clusters_arr,
                rel_source,
                expr_point,
                fn_dist,
                'madlib.avg',
                20::integer,
                0.001::double precision,
                1.0::double precision
            ) into ret;
        return ret;
    end;

$$ language plpgsql;

CREATE OR REPLACE FUNCTION PDLTOOLS_SCHEMA.gs_kmeanspp(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],
    rel_source text,
    expr_point text
) returns text AS 
$$
    declare 
        ret text;
    begin
        select PDLTOOLS_SCHEMA.gs_kmeanspp(
                id_column,
                mdl_output_tbl,
                num_clusters_arr,
                rel_source,
                expr_point,
                'madlib.squared_dist_norm2',
                'madlib.avg',
                20::integer,
                0.001::double precision,
                1.0::double precision
            ) into ret;
        return ret;
    end;

$$ language plpgsql;

/*=============================================================================
* kmeans random
=============================================================================*/
drop function if exists PDLTOOLS_SCHEMA.gs_kmeans_random(
    text, 
    text, 
    int[],
    text, 
    text, 
    text, 
    text,
    integer,
    double precision
) cascade;
create or replace function PDLTOOLS_SCHEMA.gs_kmeans_random(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],

    rel_source text,
    expr_point text,
    fn_dist text, -- optional, default: 'squared_dist_norm2'
    agg_centroid text, -- optional, default: 'avg'
    max_num_iterations integer, -- optional, default: 20
    min_frac_reassigned double precision -- optional, default: 0.001
)
returns text
as
$$
    import plpy

    #1) Create kmeanspp function call
    kmeanspp_func = '''
        madlib.kmeans_random(
             ''{rel_source}'', 
             ''{expr_point}'', 
             {num_clusters}, 
             ''{fn_dist}'', 
             ''{agg_centroid}'', 
             {max_num_iterations}
         )
    '''
    
    #2) Prepare a table to hold model results
    sql = '''
    select 
        PDLTOOLS_SCHEMA.grid_search_kmeans_all(
            '{id_column}',
            '{mdl_output_tbl}',
            array{num_clusters_arr},
            '{kmeans_func}',
            '{rel_source}',
            '{expr_point}',
            '{fn_dist}',
            '{agg_centroid}',
            {max_num_iterations},
            {min_frac_reassigned},
            {seeding_sample_ratio}
        );
    '''.format(
            id_column=id_column,
            mdl_output_tbl=mdl_output_tbl,
            num_clusters_arr=num_clusters_arr,
            kmeans_func=kmeanspp_func,
            rel_source=rel_source,
            expr_point=expr_point,
            fn_dist=fn_dist,
            agg_centroid=agg_centroid,
            max_num_iterations=max_num_iterations,
            min_frac_reassigned=min_frac_reassigned,
            seeding_sample_ratio='NULL'
        )

    plpy.execute(sql)
    return 'Model parameters written to {mdl_output_tbl} table'.format(mdl_output_tbl = mdl_output_tbl) 
$$ language plpythonu;


CREATE OR REPLACE FUNCTION PDLTOOLS_SCHEMA.gs_kmeans_random(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],
    rel_source text,
    expr_point text,
    fn_dist text /*+ DEFAULT 'squared_dist_norm2' */,
    agg_centroid text /*+ DEFAULT 'avg' */,
    max_num_iterations integer /*+ DEFAULT 20 */
) returns text AS 
$$
    declare 
        ret text;
    begin
        select PDLTOOLS_SCHEMA.gs_kmeans_random(
                id_column,
                mdl_output_tbl,
                num_clusters_arr,
                rel_source,
                expr_point,
                fn_dist,
                agg_centroid,
                max_num_iterations,
                0.001::double precision
            ) into ret;
        return ret;
    end;

$$ language plpgsql;


CREATE OR REPLACE FUNCTION PDLTOOLS_SCHEMA.gs_kmeans_random(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],
    rel_source text,
    expr_point text,
    fn_dist text /*+ DEFAULT 'squared_dist_norm2' */,
    agg_centroid text /*+ DEFAULT 'avg' */
) returns text AS 
$$
    declare 
        ret text;
    begin
        select PDLTOOLS_SCHEMA.gs_kmeans_random(
                id_column,
                mdl_output_tbl,
                num_clusters_arr,
                rel_source,
                expr_point,
                fn_dist,
                agg_centroid,
                20::integer,
                0.001::double precision
            ) into ret;
        return ret;
    end;

$$ language plpgsql;


CREATE OR REPLACE FUNCTION PDLTOOLS_SCHEMA.gs_kmeans_random(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],
    rel_source text,
    expr_point text,
    fn_dist text /*+ DEFAULT 'squared_dist_norm2' */
) returns text AS 
$$
    declare 
        ret text;
    begin
        select PDLTOOLS_SCHEMA.gs_kmeans_random(
                id_column,
                mdl_output_tbl,
                num_clusters_arr,
                rel_source,
                expr_point,
                fn_dist,
                'madlib.avg',
                20::integer,
                0.001::double precision
            ) into ret;
        return ret;
    end;

$$ language plpgsql;


CREATE OR REPLACE FUNCTION PDLTOOLS_SCHEMA.gs_kmeans_random(
    id_column text,
    mdl_output_tbl text,
    num_clusters_arr int[],
    rel_source text,
    expr_point text
) returns text AS 
$$
    declare 
        ret text;
    begin
        select PDLTOOLS_SCHEMA.gs_kmeans_random(
                id_column,
                mdl_output_tbl,
                num_clusters_arr,
                rel_source,
                expr_point,
                'madlib.squared_dist_norm2',
                'madlib.avg',
                20::integer,
                0.001::double precision
            ) into ret;
        return ret;
    end;

$$ language plpgsql;

/*=============================================================================
* Elastic Net 
=============================================================================*/
drop function if exists PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text, -- input table
    tbl_result text, -- results of grid search 
    col_dep_var text, -- name of label column in input table
    col_ind_var text, -- name of features column in input table
    regress_family text, -- regression type
    alphas float8[],  -- list of possible value for alpha
    lambdas float8[], -- list of possible values for lambdas
    id_column text, -- name of id column in input table
    mdl_table text, -- intermediate table to store elastic net models
    k_folds int, -- number of folds
    standardize boolean, -- OPTIONAL: whether to normalize the data, default: TRUE
    optimizer text, -- OPTIONAL: name of optimizer, either 'fista' or 'igd', default: 'fista'
    optimizer_params text, -- OPTIONAL: optimizer parameters, delimited with commas, defaut: NULL
    excluded text, -- OPTIONAL: If the col_ind_var input is '*' then excluded can be provided as a comma-delimited list of column names that are to be excluded from the features, default: NULL
    max_iter integer, -- OPTIONAL: the maximum number of iterations that are allowed, default: 1000
    tolerance float8 -- OPTIONAL: criteria to end iterations, default is 1e-6
);




create or replace function PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text, -- input table
    tbl_result text, -- results of grid search 
    col_dep_var text, -- name of label column in input table
    col_ind_var text, -- name of features column in input table
    regress_family text, -- regression type
    alphas float8[],  -- list of possible value for alpha
    lambdas float8[], -- list of possible values for lambdas
    id_column text, -- name of id column in input table
    mdl_table text, -- intermediate table to store elastic net models
    k_folds int, -- number of folds
    standardize boolean, -- OPTIONAL: whether to normalize the data, default: TRUE
    optimizer text, -- OPTIONAL: name of optimizer, either 'fista' or 'igd', default: 'fista'
    optimizer_params text, -- OPTIONAL: optimizer parameters, delimited with commas, defaut: NULL
    excluded text, -- OPTIONAL: If the col_ind_var input is '*' then excluded can be provided as a comma-delimited list of column names that are to be excluded from the features, default: NULL
    max_iter integer, -- OPTIONAL: the maximum number of iterations that are allowed, default: 1000
    tolerance float8 -- OPTIONAL: criteria to end iterations, default is 1e-6
)
returns text
as
$$
    import plpy
    from itertools import product

    cv_set = """
        drop table if exists tbl_source_cv;
        create temp table tbl_source_cv
        as
        (
            select
                *,
                random() as cv_select
            from
                {tbl_source}
        );
    """.format(
        tbl_source = tbl_source
    )
    plpy.execute(cv_set)

    #training set creation
    training_set = """
        drop table if exists tbl_source_training_set_cv cascade;
        create temp table tbl_source_training_set_cv
        as
        (
            select
                *
            from
                tbl_source_cv
            where 
                cv_select not between {lower_bound} and {upper_bound}
        );
    """

    #test set creation
    test_set = """
        drop table if exists tbl_source_test_set_cv cascade;
        create temp table tbl_source_test_set_cv
        as
        (
            select
                *
            from
                tbl_source_cv
            where 
                cv_select between {lower_bound} and {upper_bound}
        );            
    """

    #model training code
    mdl_train = """
        drop table if exists {mdl_table};
        select 
            madlib.elastic_net_train( 
                '{tbl_source}', --tbl_source
                '{mdl_table}', --tbl_result,
                '{col_dep_var}', --col_dep_var,
                '{col_ind_var}', --col_ind_var,
                '{regress_family}', --regress_family,
                {alpha}, --alpha (=1 => L1, =0 => L2),
                {lamda}, --lambda_value,
                {standardize}, --standardize,
                NULL, --grouping_col,
                '{optimizer}', --optimizer,
                '{optimizer_params}', --optimizer_params,
                '{excluded}', --excluded,
                {max_iter}, --max_iter,
                {tolerance} --tolerance
            );
    """

    mdl_score="""
        drop table if exists tbl_source_test_set_cv_results cascade;
        create temp table tbl_source_test_set_cv_results
        as
        (
            select
                {id_column},
                {col_dep_var} as actual_label,
                madlib.elastic_net_binomial_predict(
                    coef_all,
                    intercept,
                    {col_ind_var}
                ) as predicted_label,            
                madlib.elastic_net_binomial_prob(
                    coef_all,
                    intercept,
                    {col_ind_var}
                ) as predicted_label_proba
            from
                {cv_model} mdl,
                {test_set} test
        ) distributed randomly;        
    """

    #output table CTAS
    tbl_result_ctas = """
        --drop table if exists {tbl_result} cascade;
        create table {tbl_result}
        (
            alpha float8,
            lamda float8,
            fold int,
            auc float8
        )distributed randomly;
    """
    plpy.execute(tbl_result_ctas.format(tbl_result=tbl_result))

    iter = 0
    for alpha, lamda in product(alphas, lambdas):
        plpy.info('Iteration {0} of {1}'.format(iter, len(list(product(alphas, lambdas)))))
        plpy.info('alpha:{0}, lambda:{1}'.format(alpha, lamda))
        for fold in range(k_folds):
            lower_bound = fold*(1.0/k_folds)
            upper_bound = (fold+1)*(1.0/k_folds)

            #create training & test set
            plpy.execute(training_set.format(lower_bound=lower_bound, upper_bound=upper_bound))
            plpy.execute(test_set.format(lower_bound=lower_bound, upper_bound=upper_bound))
            #train model
            plpy.execute(
                mdl_train.format(
                    alpha=alpha, 
                    lamda=lamda, 
                    tbl_source='tbl_source_training_set_cv',
                    mdl_table=mdl_table,
                    col_dep_var=col_dep_var,
                    col_ind_var=col_ind_var,
                    regress_family=regress_family,
                    standardize=standardize,
                    optimizer=optimizer,
                    optimizer_params=optimizer_params,
                    excluded=excluded,
                    max_iter=max_iter,
                    tolerance=tolerance
                ).replace("'None'","NULL")
            )

            #score on test set
            plpy.execute(
                mdl_score.format(
                    cv_model=mdl_table, 
                    test_set='tbl_source_test_set_cv',
                    id_column=id_column,
                    col_dep_var=col_dep_var,
                    col_ind_var=col_ind_var
                )
            )

            #Compute AUC and insert metrics into results table
            auc_sql = """
                insert into {tbl_result}
                select
                    {alpha} as alpha,
                    {lamda} as lambda,         
                    {fold} as fold,
                    pdltools.mf_auc(
                        'tbl_source_test_set_cv_results',
                        'predicted_label_proba', -- predicted probabilities
                        'actual_label' -- actual column
                    ) as auc
            """.format(
                alpha=alpha,
                lamda=lamda,
                fold=fold,
                tbl_result=tbl_result
            )
            plpy.execute(auc_sql)

        iter+=1
    return 'Grid search results written to {tbl_result}'.format(tbl_result=tbl_result)  
$$language plpythonu;


-- overloading functions
drop function if exists PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean, --optional, defualt: True
    optimizer text, --optional, defualt: 'fista'
    optimizer_params text, --optional, default: NULL
    excluded text, --optional, default: NULL
    max_iter integer --optional, default: 1000
);
create or replace function PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean, --optional, defualt: True
    optimizer text, --optional, defualt: 'fista'
    optimizer_params text, --optional, default: NULL
    excluded text, --optional, default: NULL
    max_iter integer --optional, default: 1000
) 
returns text 
as 
$$
    declare 
        ret text;
    begin 
        select PDLTOOLS_SCHEMA.gs_elasticnet_cv(
            tbl_source,
            tbl_result,
            col_dep_var,
            col_ind_var,
            regress_family,
            alphas,
            lambdas,
            id_column,
            mdl_table,
            k_folds,
            standardize,
            optimizer,
            optimizer_params,
            excluded,
            max_iter,
            1e-6) into ret;
        return ret;
    end;
$$ language plpgsql;


drop function if exists PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean, --optional, defualt: True
    optimizer text, --optional, defualt: 'fista'
    optimizer_params text, --optional, default: NULL
    excluded text --optional, default: NULL
);
create or replace function PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean, --optional, defualt: True
    optimizer text, --optional, defualt: 'fista'
    optimizer_params text, --optional, default: NULL
    excluded text --optional, default: NULL
) 
returns text 
as
$$
    declare 
        ret text;
    begin 
        select PDLTOOLS_SCHEMA.gs_elasticnet_cv(
            tbl_source,
            tbl_result,
            col_dep_var,
            col_ind_var,
            regress_family,
            alphas,
            lambdas,
            id_column,
            mdl_table,
            k_folds,
            standardize,
            optimizer,
            optimizer_params,
            excluded,
            1000) into ret;
        return ret;
    end;
$$ language plpgsql;


drop function if exists PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean, --optional, defualt: True
    optimizer text, --optional, defualt: 'fista'
    optimizer_params text --optional, default: NULL
);
create or replace function PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean, --optional, defualt: True
    optimizer text, --optional, defualt: 'fista'
    optimizer_params text --optional, default: NULL
) 
returns text 
as
$$
    declare 
        ret text;
    begin 
        select PDLTOOLS_SCHEMA.gs_elasticnet_cv(
            tbl_source,
            tbl_result,
            col_dep_var,
            col_ind_var,
            regress_family,
            alphas,
            lambdas,
            id_column,
            mdl_table,
            k_folds,
            standardize,
            optimizer,
            optimizer_params,
            NULL) into ret;
        return ret;
    end;
$$ language plpgsql;

drop function if exists PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean, --optional, defualt: True
    optimizer text --optional, defualt: 'fista'
);
create or replace function PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean, --optional, defualt: True
    optimizer text --optional, defualt: 'fista'
) 
returns text 
as
$$
    declare 
        ret text;
    begin 
        select PDLTOOLS_SCHEMA.gs_elasticnet_cv(
            tbl_source,
            tbl_result,
            col_dep_var,
            col_ind_var,
            regress_family,
            alphas,
            lambdas,
            id_column,
            mdl_table,
            k_folds,
            standardize,
            optimizer,
            NULL) into ret;
        return ret;
    end;
$$ language plpgsql;


drop function if exists PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean --optional, defualt: True
);
create or replace function PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int,
    standardize boolean --optional, defualt: True
) 
returns text 
as
$$
    declare 
        ret text;
    begin 
        select PDLTOOLS_SCHEMA.gs_elasticnet_cv(
            tbl_source,
            tbl_result,
            col_dep_var,
            col_ind_var,
            regress_family,
            alphas,
            lambdas,
            id_column,
            mdl_table,
            k_folds,
            standardize,
            'fista') into ret;
        return ret;
    end;
$$ language plpgsql;

drop function if exists PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int
);
create or replace function PDLTOOLS_SCHEMA.gs_elasticnet_cv(
    tbl_source text,
    tbl_result text,
    col_dep_var text,
    col_ind_var text,
    regress_family text,
    alphas float8[],
    lambdas float8[],
    id_column text,
    mdl_table text,
    k_folds int
) 
returns text 
as
$$
    declare 
        ret text;
    begin 
        select PDLTOOLS_SCHEMA.gs_elasticnet_cv(
            tbl_source,
            tbl_result,
            col_dep_var,
            col_ind_var,
            regress_family,
            alphas,
            lambdas,
            id_column,
            mdl_table,
            k_folds,
            True) into ret;
        return ret;
    end;
$$ language plpgsql;




drop function if exists PDLTOOLS_SCHEMA.lda_gridsearch(
        alphas float8[], 
        betas float8[], 
        num_topics_arr int[],
        input_table text,
        mdl_table text,
        output_table text
    );
    create or replace function PDLTOOLS_SCHEMA.lda_gridsearch(
        alphas float8[],
        betas float8[],
        num_topics_arr int[],
        input_table text,
        mdl_table text,
        output_table text
    )
    returns text
    as
    $$
        import plpy
        from itertools import product
        #Get vocabulary size
        voc_size = plpy.execute(
            """
                select 
                    count(distinct wordid) as voc_size 
                from 
                    {input_table}
            """.format(
                input_table=input_table
            )
        )[0]['voc_size']
        
        mdl = """
            drop table if exists {mdl_table} cascade;
            drop table if exists {mdl_table}_results cascade;
            select 
                madlib.lda_train(
                    '{input_table}', -- data_table',
                    '{mdl_table}', -- model_table',
                    '{mdl_table}_results', -- output_data_table',
                    {voc_size}, -- voc_size,
                    {num_topics}, -- topic_num,
                    50, -- iter_num,
                    {alpha}, -- alpha (recommended = 50/topic_num),
                    {beta} -- beta
                );
        """
        first_step = True
        iter = 0
        for alpha, beta, num_topics in product(alphas, betas, num_topics_arr):
            plpy.info('Iteration {0} of {1}'.format(iter, len(list(product(alphas, betas, num_topics_arr)))))
            plpy.info('alpha:{0}, beta:{1}, num_topics: {2}'.format(alpha, beta, num_topics))
            plpy.execute(
                mdl.format(
                    voc_size=voc_size,
                    alpha=alpha,
                    beta=beta,
                    num_topics=num_topics,
                    input_table=input_table,
                    mdl_table=mdl_table
                )
            )
            if(first_step):
                output_tbl_ctas_sql = """
                    drop table if exists {output_table};
                    create table {output_table}
                    as
                    (
                        select 
                            t1.*,
                            t2.*
                        from
                            {mdl_table} t1,
                            --Perplexity
                            (
                                select
                                    madlib.lda_get_perplexity(
                                        '{mdl_table}',
                                        '{mdl_table}_results'
                                    )
                                
                            ) t2
                    ) distributed randomly;
                """
                plpy.execute(
                    output_tbl_ctas_sql.format(
                        output_table=output_table,
                        mdl_table=mdl_table
                    )
                )
                first_step = False
            else:
                output_tbl_insert_sql = """
                    insert into {output_table}
                    select 
                        t1.*,
                        t2.*
                    from
                        {mdl_table} t1,
                        --Perplexity
                        (
                            select
                                madlib.lda_get_perplexity(
                                    '{mdl_table}',
                                    '{mdl_table}_results'
                                )

                        ) t2
                """
                plpy.execute(
                    output_tbl_insert_sql.format(
                        output_table=output_table,
                        mdl_table=mdl_table
                    )
                )
                
            iter += 1
        return 'Grid search results written to {output_table}'.format(output_table=output_table)  
    $$language plpythonu;
